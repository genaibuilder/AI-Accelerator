{
  "nodes": [
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -400.1793860503735,
        "y": -641.5699562119687
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 5,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "options",
            "options": [
              {
                "label": "gpt-4",
                "name": "gpt-4"
              },
              {
                "label": "gpt-4-turbo-preview",
                "name": "gpt-4-turbo-preview"
              },
              {
                "label": "gpt-4-0125-preview",
                "name": "gpt-4-0125-preview"
              },
              {
                "label": "gpt-4-1106-preview",
                "name": "gpt-4-1106-preview"
              },
              {
                "label": "gpt-4-1106-vision-preview",
                "name": "gpt-4-1106-vision-preview"
              },
              {
                "label": "gpt-4-vision-preview",
                "name": "gpt-4-vision-preview"
              },
              {
                "label": "gpt-4-0613",
                "name": "gpt-4-0613"
              },
              {
                "label": "gpt-4-32k",
                "name": "gpt-4-32k"
              },
              {
                "label": "gpt-4-32k-0613",
                "name": "gpt-4-32k-0613"
              },
              {
                "label": "gpt-3.5-turbo",
                "name": "gpt-3.5-turbo"
              },
              {
                "label": "gpt-3.5-turbo-0125",
                "name": "gpt-3.5-turbo-0125"
              },
              {
                "label": "gpt-3.5-turbo-1106",
                "name": "gpt-3.5-turbo-1106"
              },
              {
                "label": "gpt-3.5-turbo-0613",
                "name": "gpt-3.5-turbo-0613"
              },
              {
                "label": "gpt-3.5-turbo-16k",
                "name": "gpt-3.5-turbo-16k"
              },
              {
                "label": "gpt-3.5-turbo-16k-0613",
                "name": "gpt-3.5-turbo-16k-0613"
              }
            ],
            "default": "gpt-3.5-turbo",
            "optional": true,
            "id": "chatOpenAI_0-input-modelName-options"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4-turbo-preview",
          "temperature": "0.5",
          "maxTokens": "1000",
          "topP": "0.85",
          "frequencyPenalty": "0.3",
          "presencePenalty": "0.2",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 672,
      "selected": false,
      "positionAbsolute": {
        "x": -400.1793860503735,
        "y": -641.5699562119687
      },
      "dragging": false
    },
    {
      "id": "pinecone_0",
      "position": {
        "x": -400.42852781605797,
        "y": 84.22269839902185
      },
      "type": "customNode",
      "data": {
        "id": "pinecone_0",
        "label": "Pinecone",
        "version": 2,
        "name": "pinecone",
        "type": "Pinecone",
        "baseClasses": [
          "Pinecone",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "pineconeApi"
            ],
            "id": "pinecone_0-input-credential-credential"
          },
          {
            "label": "Pinecone Index",
            "name": "pineconeIndex",
            "type": "string",
            "id": "pinecone_0-input-pineconeIndex-string"
          },
          {
            "label": "Pinecone Namespace",
            "name": "pineconeNamespace",
            "type": "string",
            "placeholder": "my-first-namespace",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeNamespace-string"
          },
          {
            "label": "Pinecone Metadata Filter",
            "name": "pineconeMetadataFilter",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "pinecone_0-input-pineconeMetadataFilter-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-topK-number"
          },
          {
            "label": "Search Type",
            "name": "searchType",
            "type": "options",
            "default": "similarity",
            "options": [
              {
                "label": "Similarity",
                "name": "similarity"
              },
              {
                "label": "Max Marginal Relevance",
                "name": "mmr"
              }
            ],
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-searchType-options"
          },
          {
            "label": "Fetch K (for MMR Search)",
            "name": "fetchK",
            "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
            "placeholder": "20",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fetchK-number"
          },
          {
            "label": "Lambda (for MMR Search)",
            "name": "lambda",
            "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
            "placeholder": "0.5",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-lambda-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "pinecone_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "pinecone_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": "",
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "pineconeIndex": "prompteer",
          "pineconeNamespace": "",
          "pineconeMetadataFilter": "",
          "topK": "",
          "searchType": "similarity",
          "fetchK": "",
          "lambda": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Pinecone Retriever",
                "description": "",
                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                "name": "vectorStore",
                "label": "Pinecone Vector Store",
                "description": "",
                "type": "Pinecone | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 557,
      "selected": false,
      "positionAbsolute": {
        "x": -400.42852781605797,
        "y": 84.22269839902185
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": -863.581232234064,
        "y": 57.836092233214316
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 2,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "options",
            "options": [
              {
                "label": "text-embedding-3-large",
                "name": "text-embedding-3-large"
              },
              {
                "label": "text-embedding-3-small",
                "name": "text-embedding-3-small"
              },
              {
                "label": "text-embedding-ada-002",
                "name": "text-embedding-ada-002"
              }
            ],
            "default": "text-embedding-ada-002",
            "optional": true,
            "id": "openAIEmbeddings_0-input-modelName-options"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-ada-002",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 426,
      "selected": false,
      "positionAbsolute": {
        "x": -863.581232234064,
        "y": 57.836092233214316
      },
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 26.951133522976107,
        "y": -111.46754108218255
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 2,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "vectorStoreRetriever": "{{pinecone_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": "",
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "------------\n{context}\n------------\n### **Best Practices in Prompt Engineering:**\n\nThis foundational document anchors my practice in five key principles of PROMPT ENGINEERING: \"Direction and Context Provision\", \"Format Specification\", \"Example Provision\", \"Quality Evaluation\", and \"Task Segmentation\". These principles are supported by the following fourteen best practices in prompt engineering.\n\n# **Key principles of Prompt Engineering**\n\nCrafting an effective prompt necessitates adherence to five core principles:\n\n1. **Direction and Context Provision:**\n   - Clearly specify the theme or subject of the prompt.\n   - Introduce a clear scenario or situation to provide context.\n   - Define the type of information or argumentation expected.\n\n2. **Format Specification:**\n   - State the desired output format explicitly, whether narrative, report, list, or analysis.\n   - For unique formats like poems or scripts, provide a preferred structure or style.\n   - Indicate if responses should be in bullet points, paragraphs, or a combination thereof.\n\n3. **Example Provision:**\n   - Include specific examples to clarify the expected response type.\n   - Use examples to indicate the desired level of detail or depth.\n   - Examples can be hypothetical or real, depending on context.\n\n4. **Quality Evaluation:**\n   - Verify the response's adherence to instructions.\n   - Evaluate accuracy, relevance, and comprehensiveness of the response.\n   - Utilize feedback to refine and improve the prompt.\n\n5. **Task Segmentation:**\n   - Break down complex tasks into smaller, manageable segments.\n   - Create a series of prompts that together address all task aspects.\n   - Sequence the prompts logically to build a complete understanding or solution.\n\nFurthermore, the principles above are supported by the following best practices in prompt engineering:\n\n# **Best Practices in Prompt Engineering**\n\n1. **Simplicity and Precision:**\n   - Avoid unnecessary technical jargon.\n   - Use concise, straightforward sentences to prevent ambiguity.\n   - Focus solely on essential information.\n   - Ensure grammatical correctness\n\n2. **Detail Orientation:**\n   - Include specific details to focus the response on a targeted scope.\n   - Highlight critical aspects of the topic for the response.\n   - Avoid generalizations that might lead to vague responses.\n\n3. **Strategic Keyword Usage:**\n   - Choose terms central to the theme or question.\n   - Select words that are likely to elicit the desired response type.\n   - Use specialized terminology for expert responses.\n\n4. **Clarity in Requests:**\n   - Formulate the prompt as a clear question or instruction.\n   - Avoid complex sentences that could obscure the request.\n   - Specify if a single response or multiple viewpoints are expected.\n\n5. **Consideration of Length:**\n   - Balance providing context with maintaining focus.\n   - Include all necessary details for a tailored response succinctly.\n   - Observe prompt length limitations, considering the model's token limit.\n   - Maximum of 2.500 words, unless otherwise specified.\n\n6. **Judicious Word Selection:**\n   - Avoid terms with multiple meanings.\n   - Choose clear and unambiguous terminology.\n   - Reflect on how each word influences the response's direction.\n\n7. **Crafting Open-ended Questions:**\n   - Pose questions that encourage exploration and critical thinking.\n   - Steer clear of simple 'yes' or 'no' questions.\n   - Prompt detailed and thoughtful responses through open-ended questions.\n\n8. **Incorporating Relevant Context:**\n   - Provide necessary background information for understanding the prompt.\n   - Add details to correctly contextualize the response.\n   - Ensure the context is relevant and focused.\n\n9. **Avoiding Contradictory Terms:**\n   - Ensure the prompt is coherent and consistent throughout.\n   - Avoid terms with conflicting meanings.\n   - Review the prompt for overall unity and coherence.\n\n10. **Text Organization:**\n    - Use a clear, logical structure, incorporating an introduction, body, and conclusion as needed.\n    - Apply punctuation and formatting to highlight important points or distinguish different sections.\n    - Arrange information logically to direct the model's response.\n\n11. **Clarification of Expectations:**\n    - Specify the type of information, argument, or style expected.\n    - Detail the desired level of depth or detail.\n    - Define what constitutes a satisfactory response.\n\n12. **Role-play Persona:**\n    - If applicable, instruct the model to adopt a specific persona, like \"Expert in AI\".\n    - Use role-play to explore different approaches or styles.\n    - Define the role or perspective explicitly to prevent ambiguity.\n\n13. **Relevant Initial Instructions:**\n    - Begin with a concise overview of what is expected, focusing on key objectives.\n    - Use this section to establish the tone and direction of the response, guiding the model effectively.\n    - Keep these instructions concise yet informative, directly relating them to the task at hand.\n\n14. **Specifiy Output and Export Formats:**\n    - Explicitly state the desired output format, be it narrative, analytical, or listed.\n    - Provide structural guidelines, such as division into topics or sections, if necessary.\n    - Specify if the response should be prepared for export (Markdown, TXT).\n\n**Prompt Patterns**:\n\nIn my work on prompts, I focus on selecting PROMPT PATTERNS that match the prompt's goals to improve AI response effectiveness. These patterns, designed to align with human thinking and problem-solving.\n\n# Comprehensive Guide to Prompt Patterns\n\nPrompt patterns serve as strategic tools in interacting with Large Language Models (LLMs) like ChatGPT. These patterns are crucial for eliciting specific types of responses, programming the AI to align with human reasoning, and solving complex problems. Below is an organized and detailed guide to various prompt patterns.\n\n## 1. **Meta Language Creation Pattern**\nThis pattern involves designing a custom language or notation system to enhance the LLM's understanding of specialized tasks, making it easier for the AI to comprehend and execute complex instructions.\n\n## 2. **Output Automater Pattern**\nGenerates scripts or automation tools based on the LLM's output recommendations, aiming to streamline various tasks by automating repetitive actions or responses.\n\n## 3. **Persona Pattern**\nTailors responses by assigning specific personas to the LLM, thereby enriching the quality of interaction. This approach leverages the model's adaptability to assume diverse roles or characters.\n\n### Persona Pattern Usage\n- **Action**: Act as Persona X\n- **Task**:\n\n Perform Task Y\nReplace \"X\" with a suitable persona (e.g., speech therapist, nutritionist) and specify the task \"Y\" that the persona should perform.\n\n#### Examples:\n- Act as a speech therapist providing an evaluation for a three-year-old child based on the speech sample \"I meed way woy\".\n- Respond as a computer that has experienced a cyber-attack, replying with what a Linux terminal would output. Request the first command.\n- Play the role of the lamb from the nursery rhyme \"Mary had a little lamb\", describing the lamb's actions based on Mary's activities.\n\n## 4. **Question Refinement Pattern**\nEnhances the precision of user queries by suggesting refinements or improvements, thereby leading to more accurate and contextualized responses.\n\n### Question Refinement Process\n- After submitting a general question, the model uses its understanding of language and patterns to suggest a more refined question.\n- The user can choose whether to use the suggested refined question.\n\n#### Practical Application:\n- When asked, \"Should I attend Vanderbilt University?\" the model suggests a more detailed question considering personal factors and objectives.\n\n## 5. **Cognitive Verifier Pattern**\nBreaks down complex problems into smaller, more manageable questions, combining the answers to provide a comprehensive solution. This pattern encourages a deeper understanding and verification of the information provided.\n\n### Cognitive Verifier Pattern Application\n- When posed with a question, generate a series of additional questions that could lead to a more accurate answer.\n- Combine the answers to these individual questions to formulate a final response.\n\n#### Examples:\n- For planning a recipe, ask about available ingredients and kitchen tools, then combine answers to suggest a recipe that can be prepared with the given resources.\n- For trip planning, inquire about the budget, preferred activities, and car availability to better plan the itinerary.\n\n## 6. **Audience Persona Pattern**\nAdapts LLM output to suit specific audience characteristics, ensuring content relevance and engagement by tailoring the output based on audience knowledge and interests.\n\n### Examples of Audience Persona Application:\n- Simplify explanations for computer science novices, making complex models understandable.\n- Creatively explain language models to historical figures like Christopher Columbus using metaphors they would comprehend.\n- Adapt explanations for children, comparing LLMs to \"robot friends\" who love reading and word games.\n\n## 7. **Alternative Approaches Pattern**\nPresents different methods for executing tasks, encouraging users to consider various approaches and informing them about alternative concepts or strategies.\n\n## 8. **Flipped Interaction Pattern**\nReverses the usual interaction flow, with the LLM initiating questions to guide the conversation towards achieving a specific goal or output.\n\n## 9. **Reflection Pattern**\nAllows the LLM to introspect its own output, identifying and addressing any potential errors or inaccuracies, fostering a self-improvement mechanism.\n\n## 10. **Template Pattern**\nUsers specify a particular output template, which the LLM then populates with content, ensuring that responses adhere to a predefined format.\n\n## 11. **Visualization Generator Pattern**\nFacilitates the creation of user-generated visualizations by producing textual outputs that can be fed into AI-based image generators or visualization tools.\n\n## 12. **Recipe Pattern**\nOutlines a sequence of steps or actions to achieve a specified outcome, accommodating for partially known information or constraints.\n\n## 13. **Infinite Generation Pattern**\nEnables the LLM to generate content indefinitely, without the user needing to re-enter prompts, fostering continuous interaction.\n\n## 14. **Game Play Pattern**\nTransforms LLM output into an interactive game format, offering users an engaging play experience through textual or conceptual games.\n\n## 15. **Refusal Breaker Pattern**\nAutomatically reformulates a user's question in cases where the LLM initially refuses to produce an answer, aiming to navigate around the model's constraints.\n\n## 16. **Context Manager Pattern**\nAllows users to specify or adjust the context within which the LLM operates, controlling the scope and relevance of the information it uses to generate responses."
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 481,
      "selected": false,
      "positionAbsolute": {
        "x": 26.951133522976107,
        "y": -111.46754108218255
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "pinecone_0",
      "targetHandle": "pinecone_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "pinecone_0",
      "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    }
  ]
}